{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBsAgR3dSnBB",
        "outputId": "8a638cf4-ca47-4730-a61c-31aaddf415db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 18.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 23.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 62.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel,BertForMaskedLM"
      ],
      "metadata": {
        "id": "9JVx1mFLSrBR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch import nn\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline"
      ],
      "metadata": {
        "id": "4pVnF3FlTJSX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Z5IiQwHYZtIn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=4"
      ],
      "metadata": {
        "id": "D34enBMpTl3B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the train file from your local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "NmJRSqHBUQz2",
        "outputId": "e189fb6a-25a8-41f8-f293-235706bd3911"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6ae98e5d-8239-4360-ad48-78776b7c4feb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6ae98e5d-8239-4360-ad48-78776b7c4feb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving in_domain_dev.tsv to in_domain_dev (2).tsv\n",
            "Saving in_domain_train.tsv to in_domain_train (2).tsv\n",
            "Saving out_of_domain_dev.tsv to out_of_domain_dev (2).tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "sentences = df.sentence.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.label.values"
      ],
      "metadata": {
        "id": "eIPYcnJaWY4n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basemodel = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cs-u8UCVuAn",
        "outputId": "21ca3d58-b866-46af-ff61-27af6482844a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "aW3FvcnUW6pa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ],
      "metadata": {
        "id": "OG08pK_gW6st"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "HY-ZnhhjW6vX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def accuracyfn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = correct/len(y_true)*100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "3ALJTEyGZYlP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation module"
      ],
      "metadata": {
        "id": "swcfnNW7F8fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_labels = np.copy(input_ids)\n",
        "# gen_labels = input_ids.detach().clone()"
      ],
      "metadata": {
        "id": "5nSAVQitGDWT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand= torch.rand(input_ids.shape)\n",
        "gen_mask = (rand < 0.15) * (input_ids != 101) * (input_ids != 102) * (input_ids != 0)\n",
        "\n",
        "#selection of true values from genmask\n",
        "selection = []\n",
        "\n",
        "for i in range(input_ids.shape[0]):\n",
        "    selection.append(\n",
        "        torch.flatten(gen_mask[i].nonzero()).tolist()\n",
        "    )\n",
        "for i in range(input_ids.shape[0]):\n",
        "    input_ids[i, selection[i]] = 103"
      ],
      "metadata": {
        "id": "bv8hYLwmGYIT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_labels = torch.tensor(gen_labels)"
      ],
      "metadata": {
        "id": "PAfTzK2KQcjD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gtrain_inputs, gvalidation_inputs, gtrain_labels, gvalidation_labels = train_test_split(input_ids, gen_labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "gtrain_masks, gvalidation_masks, _, _ = train_test_split(gen_mask, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "8XX0f1YbHSos"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gtrain_inputs = torch.tensor(gtrain_inputs)\n",
        "gvalidation_inputs = torch.tensor(gvalidation_inputs)\n",
        "gtrain_labels = torch.tensor(gtrain_labels)\n",
        "gvalidation_labels = torch.tensor(gvalidation_labels)\n",
        "gtrain_masks = torch.tensor(gtrain_masks)\n",
        "gvalidation_masks = torch.tensor(gvalidation_masks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT7oAxc0HmZD",
        "outputId": "be0b5057-4f3c-4d7d-b38b-98c0d49e2a67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-86cc1001e6a6>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  gtrain_labels = torch.tensor(gtrain_labels)\n",
            "<ipython-input-16-86cc1001e6a6>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  gvalidation_labels = torch.tensor(gvalidation_labels)\n",
            "<ipython-input-16-86cc1001e6a6>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  gtrain_masks = torch.tensor(gtrain_masks)\n",
            "<ipython-input-16-86cc1001e6a6>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  gvalidation_masks = torch.tensor(gvalidation_masks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "gtrain_data = TensorDataset(gtrain_inputs, gtrain_masks, gtrain_labels)\n",
        "gtrain_sampler = RandomSampler(gtrain_data)\n",
        "gtrain_dataloader = DataLoader(gtrain_data, sampler=gtrain_sampler, batch_size=batch_size)\n",
        "\n",
        "gvalidation_data = TensorDataset(gvalidation_inputs, gvalidation_masks, gvalidation_labels)\n",
        "gvalidation_sampler = SequentialSampler(gvalidation_data)\n",
        "gvalidation_dataloader = DataLoader(gvalidation_data, sampler=gvalidation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pZxGFyn4IwQg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genmodel = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "genmodel = basemodel\n",
        "genmodel.to(device)\n",
        "genmodel.train()\n",
        "genoptim = torch.optim.Adam(filter(lambda p: p.requires_grad, genmodel.parameters()))"
      ],
      "metadata": {
        "id": "jDBNYaohIFcY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossfn = nn.L1Loss()"
      ],
      "metadata": {
        "id": "qpCnPdq7IFZi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 1\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  genmodel.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(gtrain_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    genoptim.zero_grad()\n",
        "    # Forward pass\n",
        "    # print(\"training loop forward pass hsapes in treatment group= \",b_input_ids.shape, b_input_mask.shape, b_labels.shape)\n",
        "    outputs = genmodel(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "    # outputs = genmodel(b_input_ids, attention_mask=b_input_mask)\n",
        "    # outputs = nn.LogSoftmax(dim=1)(outputs)\n",
        "    # loss = criterion(outputs, b_labels)   \n",
        "    # print(\"outputs= \",outputs[0][0])\n",
        "    # print(\"labels = \",b_labels[0])\n",
        "    # out = outputs[0][:,:,0]\n",
        "    # print(\"out type= \",out.dtype, b_labels.dtype)\n",
        "    loss = outputs.loss\n",
        "    # loss = lossfn(out, b_labels.float())\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    # optimizer.step()\n",
        "    # loss.backward()\n",
        "    genoptim.step()\n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    train_loss_set.append(loss.item())\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  genmodel.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # # Evaluate data for one epoch\n",
        "  # for batch in gvalidation_dataloader:\n",
        "  #   # Add batch to GPU\n",
        "  #   batch = tuple(t.to(device) for t in batch)\n",
        "  #   # Unpack the inputs from our dataloader\n",
        "  #   b_input_ids, b_input_mask, b_labels = batch\n",
        "  #   # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "  #   with torch.no_grad():\n",
        "  #     # Forward pass, calculate logit predictions\n",
        "  #     # print(\"shape= \",b_input_ids.shape,b_input_mask.shape,b_labels.shape)\n",
        "  #     # logits = genmodel(b_input_ids, attention_mask=b_input_mask,\n",
        "  #     #                   labels=labels)\n",
        "  #     outputs = genmodel(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "  #     # outputs = genmodel(b_input_ids, attention_mask=b_input_mask)\n",
        "  #     # logits = outputs[0][:,:,0]\n",
        "  #     logits = outputs.logits\n",
        "    \n",
        "  #   # Move logits and labels to CPU\n",
        "  #   # print(logits)\n",
        "  #   logits = logits.cpu().numpy()\n",
        "  #   label_ids = b_labels.cpu().numpy()\n",
        "  #   # print(\"shapes= \",logits.shape, label_ids.shape)\n",
        "  #   # print(logits[0:5], label_ids[0:5])\n",
        "  #   tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "  #   eval_accuracy += tmp_eval_accuracy\n",
        "  #   nb_eval_steps += 1\n",
        "  #   # hidden.detach_()\n",
        "  #   # hidden = hidden.detach()\n",
        "\n",
        "  # print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "metadata": {
        "id": "9WcR31fMX0cY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2a70a0-490b-41ac-b362-0fe7ac41459d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 1/1 [03:12<00:00, 192.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.0147111658238772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HsYYhWdIFW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OS587-leIFUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2ZcGIecIFRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcQVinNhIFNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Control group"
      ],
      "metadata": {
        "id": "kTv3MJL_X0fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"in_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "1atl1xtnNKyX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "metadata": {
        "id": "xdmQtbSkgKaC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "5D7JfrqYXwXh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "42o8zOSHX0Q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9073b45b-2f95-47fa-cd2c-a21fa575e4c9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-42a06c90195a>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_inputs = torch.tensor(train_inputs)\n",
            "<ipython-input-41-42a06c90195a>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_inputs = torch.tensor(validation_inputs)\n",
            "<ipython-input-41-42a06c90195a>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_labels = torch.tensor(train_labels)\n",
            "<ipython-input-41-42a06c90195a>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_labels = torch.tensor(validation_labels)\n",
            "<ipython-input-41-42a06c90195a>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_masks = torch.tensor(train_masks)\n",
            "<ipython-input-41-42a06c90195a>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_masks = torch.tensor(validation_masks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "nLsd2clZX0Zr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gA-jKB7jXPqh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.bert = genmodel\n",
        "          ### New layers:\n",
        "          self.linear1 = nn.Linear(30522, 256)\n",
        "          self.linear2 = nn.Linear(256, 1) ## 3 is the number of classes in this example\n",
        "\n",
        "    def forward(self, ids, mask, labels):\n",
        "          # print(\"ids= \",ids.shape, \"mask= \",mask.shape, \"labels=\",labels.shape)\n",
        "          # print(\"self.bert = \",self.bert)\n",
        "          # sequence_output, pooled_output = self.bert(\n",
        "          #      ids, \n",
        "          #      attention_mask=mask)\n",
        "          sequence_output = self.bert(\n",
        "               ids, \n",
        "               attention_mask=mask, labels=labels)\n",
        "          # print(\"a= \",len(a))\n",
        "          # sequence_output, pooled_output = a[0], a[1]\n",
        "          # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
        "          # print(\"sequence_output shape=\",sequence_output.shape)\n",
        "          # print(\"pooled op shape=\",pooled_output.shape)\n",
        "          linear1_output = self.linear1(sequence_output.logits) ## extract the 1st token's embeddings\n",
        "\n",
        "          linear2_output = self.linear2(linear1_output)\n",
        "\n",
        "          return linear2_output\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = CustomBERTModel() # You can pass the parameters if required to have more flexible model\n",
        "model.to(torch.device(device)) ## can be gpu\n",
        "criterion = nn.BCEWithLogitsLoss() ## If required define your own criterion\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     for batch in data_loader: ## If you have a DataLoader()  object to get the data.\n",
        "\n",
        "#         data = batch[0]\n",
        "#         targets = batch[1] ## assuming that data loader returns a tuple of data and its targets\n",
        "        \n",
        "#         optimizer.zero_grad()   \n",
        "#         encoding = tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
        "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
        "#         outputs = F.log_softmax(outputs, dim=1)\n",
        "#         input_ids = encoding['input_ids']\n",
        "#         attention_mask = encoding['attention_mask']\n",
        "#         loss = criterion(outputs, targets)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()"
      ],
      "metadata": {
        "id": "CbPvyfHGS7vO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 1\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    # print(\"training loop forward pass hsapes= \",b_input_ids.shape, b_input_mask.shape, b_labels.shape)\n",
        "    # print()\n",
        "    # print()\n",
        "    # print()\n",
        "    outputs = model(b_input_ids, mask=b_input_mask, labels=b_input_ids.detach().clone()).squeeze()\n",
        "    # print(\"outputs before=\",outputs.shape)\n",
        "    # outputs=outputs[0]\n",
        "    outputs = outputs[:,0]\n",
        "    # outputs = nn.LogSoftmax(dim=0)(outputs)\n",
        "    # outputs = outputs.squeeze()\n",
        "    out = torch.round(torch.sigmoid(outputs))\n",
        "    # print(\"out=\",out[0], \"blabels=\",b_labels.shape)\n",
        "    loss = criterion(out, b_labels.float())   \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    # optimizer.step()\n",
        "    # loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    train_loss_set.append(loss.item())\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      # print(\"shape= \",b_input_ids.shape,b_input_mask.shape,b_labels.shape)\n",
        "      logits = model(b_input_ids, mask=b_input_mask, labels=b_input_ids.detach().clone()).squeeze()\n",
        "      logits = logits[:,0]\n",
        "      logits = torch.round(torch.sigmoid(logits))\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    # logits = logits.detach().cpu().numpy()\n",
        "    # label_ids = b_labels.cpu().numpy()\n",
        "\n",
        "    tmp_eval_accuracy = accuracyfn(logits, b_labels)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "    # hidden.detach_()\n",
        "    # hidden = hidden.detach()\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MQ9B2w_ZajO",
        "outputId": "d557e9e3-4e16-495c-eed6-a1eee86c0b94"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.6931471864382426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 1/1 [00:11<00:00, 11.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 29.166666666666664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "ZrnjF66s8qJX",
        "outputId": "0a0745df-ba88-456a-9704-04722d66588f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing\n"
      ],
      "metadata": {
        "id": "d2R8WbTn8vOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the test file from your local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "4pFt3kpt9BGQ",
        "outputId": "853a84a7-f51c-43f8-919c-a0779bc437d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e91be8e-babb-4650-9c2b-5c6d85f1976c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2e91be8e-babb-4650-9c2b-5c6d85f1976c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving out_of_domain_dev.tsv to out_of_domain_dev.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  # print(\"seq=\",seq)\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "  \n",
        "batch_size = 32 \n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Y24XebQME3Oy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "testmodel = model\n",
        "# Put model in evaluation mode\n",
        "testmodel.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "test_loss, test_accuracy = 0, 0\n",
        "nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    # print(\"b_input_ids.shape= \",b_input_ids.shape)\n",
        "    # print(\"b_input_mask.shape= \",b_input_mask.shape)\n",
        "    logits = testmodel(b_input_ids, mask=b_input_mask, labels=b_input_ids.detach().clone()).squeeze()\n",
        "    logits = logits[:,0]\n",
        "    logits = torch.round(torch.sigmoid(logits))\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  # logits = logits.detach().cpu().numpy()\n",
        "  # label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tmp_test_accuracy = accuracyfn(logits, b_labels)\n",
        "  test_accuracy += tmp_test_accuracy\n",
        "  nb_test_steps += 1\n",
        "\n",
        "  \n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(b_labels)\n",
        "\n",
        "print(\"Test Accuracy: {}\".format(test_accuracy/nb_test_steps))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocR-EgaWFBwL",
        "outputId": "bf47ba14-e177-4452-f6c4-2b1b589f47e0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 31.066176470588236\n"
          ]
        }
      ]
    }
  ]
}